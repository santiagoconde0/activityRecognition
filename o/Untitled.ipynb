{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Session 2: Transfer Learning for Activity Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Librerires`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Data and files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\s7277028\\\\Documents\\\\ARSSD\\\\Practicas\\\\Practica1\\\\OpportunityUCIDataset\\\\dataset\\\\' \n",
    "header_path = 'C:\\\\Users\\\\s7277028\\\\Documents\\\\ARSSD\\\\Practicas\\\\Practica1\\\\header.csv' \n",
    "header=pd.read_csv(header_path, names=['column',''])['column'].values\n",
    "users = range(1,5)\n",
    "trials = range(1,7)\n",
    "all_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Read Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s7277028\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "for user in users:\n",
    "    for trial in trials:\n",
    "        if trial==6:\n",
    "            filePath= path+'S'+str(user)+'-Drill.dat'\n",
    "        else:\n",
    "            filePath = path+'S'+str(user)+'-ADL'+str(trial)+'.dat'\n",
    "        sadl1 = pd.read_csv(filePath, sep=' ', header=None)\n",
    "        data = sadl1.iloc[:, :243]\n",
    "        data.columns = header\n",
    "        data=data[data.columns[np.r_[0:1,16:19,76:79,50:53]]]\n",
    "        labels = sadl1.iloc[:,243]\n",
    "        #find and remove rows with all nulls\n",
    "        idx=data.index[data.isnull().all(1)]\n",
    "        data = data[~data.index.isin(idx)]\n",
    "        labels = labels[~labels.index.isin(idx)]\n",
    "        \n",
    "        #fill missing values\n",
    "        data = data.fillna(method='ffill',axis=1)\n",
    "        data['user'] = user\n",
    "        data['trial'] = trial\n",
    "        \n",
    "        #Pre-processing: filtering\n",
    "        #only data columns\n",
    "        columns = data.columns[~data.columns.isin(['user', 'trial', 'MILLISEC'])]\n",
    "        filtered_data = data[columns].rolling(11).median()\n",
    "        filtered_data['MILLISEC'] = data.MILLISEC\n",
    "        \n",
    "        #separate train and test'\n",
    "\n",
    "        #segmentation\n",
    "\n",
    "        filtered_data['time']=pd.to_datetime(data.MILLISEC, unit='ms')\n",
    "        filtered_data.index=filtered_data.time\n",
    "        keep = filtered_data.time.dt.microsecond/1000 %500\n",
    "        keep = keep - keep.shift() < 0\n",
    "        \n",
    "        #Feature extraction - only for first 132 columns\n",
    "        means = filtered_data[columns].rolling('1S').mean()[keep]\n",
    "        means.columns = [str(col) + '_mean' for col in means.columns]\n",
    "        variances = filtered_data[columns].rolling('1S').var()[keep]\n",
    "        variances.columns = [str(col) + '_var' for col in variances.columns]\n",
    "\n",
    "        #talk about apply function\n",
    "        labels.index = filtered_data.time\n",
    "        mode_labels = labels.rolling('1S').apply(lambda x:mode(x)[0])[keep]\n",
    "\n",
    "        #all features\n",
    "        all_features = pd.concat([means, variances], axis=1)\n",
    "        all_features['label'] = mode_labels \n",
    "        all_features['user'] = user\n",
    "        all_features['trial'] = trial\n",
    "        all_data = pd.concat([all_data, all_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accelerometer_BACK_accX_mean', 'Accelerometer_BACK_accY_mean',\n",
       "       'Accelerometer_BACK_accZ_mean', 'InertialMeasurementUnit_LUA_accX_mean',\n",
       "       'InertialMeasurementUnit_LUA_accY_mean',\n",
       "       'InertialMeasurementUnit_LUA_accZ_mean',\n",
       "       'InertialMeasurementUnit_RUA_accX_mean',\n",
       "       'InertialMeasurementUnit_RUA_accY_mean',\n",
       "       'InertialMeasurementUnit_RUA_accZ_mean', 'Accelerometer_BACK_accX_var',\n",
       "       'Accelerometer_BACK_accY_var', 'Accelerometer_BACK_accZ_var',\n",
       "       'InertialMeasurementUnit_LUA_accX_var',\n",
       "       'InertialMeasurementUnit_LUA_accY_var',\n",
       "       'InertialMeasurementUnit_LUA_accZ_var',\n",
       "       'InertialMeasurementUnit_RUA_accX_var',\n",
       "       'InertialMeasurementUnit_RUA_accY_var',\n",
       "       'InertialMeasurementUnit_RUA_accZ_var', 'label', 'user', 'trial'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the data from trials 1, 2, 3 and Drill Session as training data and the data from trials 4 and 5 as test perform two initial evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users:  {1: None, 2: None, 3: None, 4: None} | trial:  {4: None, 6: None}\n",
      "users:  {1: None, 2: None, 3: None, 4: None} | trial:  {1: None, 2: None, 3: None, 6: None}\n"
     ]
    }
   ],
   "source": [
    "#Data from trials 1,2,3 and drill with all users\n",
    "all_data_trials_1236 = all_data[all_data.trial.isin(['1','2','3','6'])]\n",
    "# #Data from user 4 with all trials\n",
    "all_data_trials_45 = all_data[all_data.trial.isin(['4','6'])]\n",
    "print(\"users: \", dict.fromkeys(all_data_trials_45.user),\"| trial: \",dict.fromkeys(all_data_trials_45.trial))\n",
    "print(\"users: \",dict.fromkeys(all_data_trials_1236.user),\"| trial: \",dict.fromkeys(all_data_trials_1236.trial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sensors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rua_sensors = ['InertialMeasurementUnit_RUA_accX_mean',\n",
    "       'InertialMeasurementUnit_RUA_accX_var',\n",
    "       'InertialMeasurementUnit_RUA_accY_mean',\n",
    "       'InertialMeasurementUnit_RUA_accY_var',\n",
    "       'InertialMeasurementUnit_LUA_accZ_mean',\n",
    "       'InertialMeasurementUnit_LUA_accZ_var','label']\n",
    "lua_sensors = ['InertialMeasurementUnit_LUA_accX_mean',\n",
    "       'InertialMeasurementUnit_LUA_accX_var',\n",
    "       'InertialMeasurementUnit_LUA_accY_mean',\n",
    "       'InertialMeasurementUnit_LUA_accY_var',\n",
    "       'InertialMeasurementUnit_LUA_accZ_mean',\n",
    "       'InertialMeasurementUnit_LUA_accZ_var', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Original and transfer tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_task = all_data[lua_sensors]\n",
    "transfer_task = all_data[rua_sensors]\n",
    "transfer_task_trials_1236 = all_data_trials_1236[rua_sensors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use data from the RUA sensor in both training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data from RUA sensor for training \n",
    "rua_training = all_data_trials_1236[rua_sensors]\n",
    "#Data from RUA sensor for testing \n",
    "rua_testing = all_data_trials_45[rua_sensors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use data from the LUA sensor as training and data from the RUA sensor as testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data from back sensor for training \n",
    "lua_training = all_data_trials_1236[lua_sensors]\n",
    "#Data from back sensor for testing \n",
    "rua_testing = all_data_trials_45[rua_sensors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer using probability distribution adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: \n",
    "### Scale the data of the original task sensor using a standard scaler to set mean 0 and std 1 https://scikitlearn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[1.94177855e+04 2.18834496e+08 2.00863024e+04 2.18569782e+08\n",
      " 2.04571760e+04 2.18483902e+08 1.63153172e+00]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-79fc69d898f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'trial'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "print(scaler.fit(original_task))\n",
    "print(scaler.mean_)\n",
    "\n",
    "X_train = train_data.loc[:,~train_data.columns.isin(['user', 'trial','label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_original_task = scaler.transform(original_task)\n",
    "scaled_original_task = pd.DataFrame(scaled_original_task, index=original_task.index, columns=original_task.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find the mean and std of the transfer sensor (trials 1, 2, 3and Drill ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InertialMeasurementUnit_RUA_accX_mean // mean:  23159.58826429697 // std:  180408.51799130425\n",
      "InertialMeasurementUnit_RUA_accX_var // mean:  236628738.69885087 // std:  11642425621.824337\n",
      "InertialMeasurementUnit_RUA_accY_mean // mean:  24122.07514511405 // std:  180281.48467186422\n",
      "InertialMeasurementUnit_RUA_accY_var // mean:  236332852.33198577 // std:  11630247143.49956\n",
      "InertialMeasurementUnit_LUA_accZ_mean // mean:  24193.05689198367 // std:  180271.98216335406\n",
      "InertialMeasurementUnit_LUA_accZ_var // mean:  236282499.35900232 // std:  11628590516.36796\n",
      "label // mean:  1.6009500626285067 // std:  1.32616813349937\n"
     ]
    }
   ],
   "source": [
    "for j in range(0, len(transfer_task_trials_1236.columns)):\n",
    "    print(transfer_task_trials_1236.columns[j] + \" // mean: \" , transfer_task_trials_1236[transfer_task_trials_1236.columns[j]].mean(), \"// std: \", transfer_task_trials_1236[transfer_task_trials_1236.columns[j]].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multiply the scaled sensor data of the original task by the std of the transfer sensor and add the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_original_task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7ce99c04716a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransfer_task_trials_1236\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransfer_task_trials_1236\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransfer_task_trials_1236\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransfer_task_trials_1236\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_original_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscaled_original_task\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mscaled_original_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscaled_original_task\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscaled_original_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscaled_original_task\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaled_original_task' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(transfer_task_trials_1236.columns)):\n",
    "    mean = transfer_task_trials_1236[transfer_task_trials_1236.columns[i]].mean()\n",
    "    std = transfer_task_trials_1236[transfer_task_trials_1236.columns[i]].std()\n",
    "    for j in range(0, len(scaled_original_task[scaled_original_task.columns[0]])):\n",
    "        scaled_original_task[scaled_original_task.columns[i]][j] = (scaled_original_task[scaled_original_task.columns[i]][j]  * std) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_original_task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-94d3753a3834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscaled_original_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscaled_original_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trial'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscaled_original_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtransfer_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtransfer_task\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trial'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaled_original_task' is not defined"
     ]
    }
   ],
   "source": [
    "scaled_original_task['user'] = all_data.user\n",
    "scaled_original_task['trial'] = all_data.trial\n",
    "scaled_original_task['label'] = all_data.label\n",
    "transfer_task['user'] = all_data.user\n",
    "transfer_task['trial'] = all_data.trial\n",
    "transfer_task['label'] = all_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled_original_task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2bca0fe9d7dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscaled_original_task\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scaled_original_task' is not defined"
     ]
    }
   ],
   "source": [
    "scaled_original_task.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier with the transformed data and test with the RUA sensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Using RUA Sensor as training and testing data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scaled_original_task\n",
    "test_data = transfer_task\n",
    "\n",
    "# Dedife train data\n",
    "X_train = train_data.loc[:,~train_data.columns.isin(['user', 'trial','label'])]\n",
    "y_train = train_data.loc[:,train_data.columns.isin(['label'])]\n",
    "\n",
    "#Define test data\n",
    "X_test = test_data.loc[:,~test_data.columns.isin(['user', 'trial','label'])]\n",
    "y_test = test_data.loc[:,test_data.columns.isin(['label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.16123075861116865\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(3)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Score: \", score)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 4., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Using LUA as training and RUA as testing data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data_trials_1236[lua_sensors]\n",
    "test_data = all_data_trials_45[rua_sensors]\n",
    "\n",
    "# Dedife train data\n",
    "X_train = train_data.loc[:,~train_data.columns.isin(['user', 'trial','label'])]\n",
    "y_train = train_data.loc[:,train_data.columns.isin(['label'])]\n",
    "\n",
    "#Define test data\n",
    "X_test = test_data.loc[:,~test_data.columns.isin(['user', 'trial','label'])]\n",
    "y_test = test_data.loc[:,test_data.columns.isin(['label'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.4174380675306356\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(3)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"Score: \", score)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer using probability distribution (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the mean and std of each class on the transfer sensor and apply the same transformation as in the previous section considering the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_task = all_data[rua_sensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
